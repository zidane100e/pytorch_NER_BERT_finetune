{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token by transformer multi-lingual\n",
    "import torch\n",
    "#from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import BertTokenizer, BertConfig, BertForTokenClassification\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "#from transformers import AutoModelForSequenceClassification, AutoModelForTokenClassification\n",
    "#from transformers import pipeline, AdamW\n",
    "from transformers import BertTokenizer, BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 75\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "config = BertConfig.from_pretrained('bert-base-multilingual-cased', output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"오에 겐자부로는 일본 현대문학의 초석을 놓은 것으로 평가받는 작가 나쓰메 소세키(1867~1916)의 대표작 ‘마음’에 담긴 군국주의적 요소, 야스쿠니 신사 참배 행위까지 소설의 삽화로 동원하며 일본 사회의 ‘비정상성’을 문제 삼는다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오', '##에', '겐', '##자', '##부', '##로는', '일본', '현대', '##문', '##학', '##의', '초', '##석', '##을', '놓', '##은', '것으로', '평', '##가', '##받', '##는', '작', '##가', '나', '##쓰', '##메', '소', '##세', '##키', '(', '1867', '~', '1916', ')', '의', '대', '##표', '##작', '[UNK]', '마', '##음', '[UNK]', '에', '담', '##긴', '군', '##국', '##주의', '##적', '요', '##소', ',', '야', '##스', '##쿠', '##니', '신', '##사', '참', '##배', '행', '##위', '##까지', '소', '##설', '##의', '삽', '##화', '##로', '동', '##원', '##하며', '일본', '사', '##회의', '[UNK]', '비', '##정', '##상', '##성', '[UNK]', '을', '문', '##제', '삼', '##는다', '.']\n",
      "{'input_ids': [101, 9580, 10530, 8873, 13764, 14646, 70186, 23130, 104518, 25934, 23321, 10459, 9757, 40958, 10622, 9029, 10892, 23925, 9926, 11287, 118965, 11018, 9652, 11287, 8982, 119103, 118927, 9448, 24982, 21039, 113, 13821, 198, 11785, 114, 9637, 9069, 37824, 38709, 100, 9246, 32158, 100, 9559, 9064, 70221, 8910, 20479, 37224, 14801, 9599, 22333, 117, 9538, 12605, 61156, 25503, 9487, 12945, 9735, 76036, 9966, 19855, 18382, 9448, 31928, 10459, 9411, 18227, 11261, 9095, 14279, 22766, 23130, 9405, 56356, 100, 9379, 16605, 14871, 17138, 100, 9633, 9297, 17730, 9410, 40410, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "# return tokens\n",
    "print(tokenizer.tokenize(text))\n",
    "# token vectorize\n",
    "# ret = {'input_ids': **, 'token_type_ids': **, 'attention_mask': **}\n",
    "print(tokenizer.encode_plus(text)) # args: pad_to_max_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   101   9580  10530   8873  13764     -1     -1     -1     -1     -1]\n",
      " [ 14646  70186  23130 104518  25934     -1     -1     -1     -1     -1]]\n"
     ]
    }
   ],
   "source": [
    "# padding (separate case with transformers)\n",
    "# use pad_sequences\n",
    "# get input of list\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tag_temp1 = tokenizer.encode_plus(text)['input_ids'][:5]\n",
    "tag_temp2 = tokenizer.encode_plus(text)['input_ids'][5:10]\n",
    "tag_temp = [tag_temp1, tag_temp2]\n",
    "tags_test = pad_sequences(tag_temp, maxlen=10, value=-1, \\\n",
    "                     padding=\"post\", dtype=\"long\", truncating=\"post\")\n",
    "print(tags_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKT KoBERT\n",
    "import gluonnlp as nlp\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "from transformers import BertTokenizer, BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "# get_pytorch_kobert_model gives model and vocab\n",
    "kobert, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "# KoBERT tokenizer\n",
    "tokenizer = nlp.data.BERTSPTokenizer(get_tokenizer(), vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오에 겐자부로는 일본 현대문학의 초석을 놓은 것으로 평가받는 작가 나쓰메 소세키(1867~1916)의 대표작 ‘마음’에 담긴 군국주의적 요소, 야스쿠니 신사 참배 행위까지 소설의 삽화로 동원하며 일본 사회의 ‘비정상성’을 문제 삼는다.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁오', '에', '▁', '겐', '자', '부', '로', '는', '▁일본', '▁현대', '문학', '의', '▁초', '석', '을', '▁놓', '은', '▁것으로', '▁평가', '받는', '▁작가', '▁나', '쓰', '메', '▁소', '세', '키', '▁(', '▁18', '67', '▁', '~', '▁19', '16', '▁', ')', '▁', '의', '▁대표', '작', '▁‘', '▁마음', '▁', '’', '▁', '에', '▁담긴', '▁군', '국', '주의', '적', '▁요소', '▁', ',', '▁야', '스', '쿠', '니', '▁신', '사', '▁참', '배', '▁행위', '까지', '▁소설', '의', '▁', '삽', '화', '로', '▁동원', '하며', '▁일본', '▁사회', '의', '▁‘', '▁비', '정', '상', '성', '▁', '’', '▁', '을', '▁문제', '▁삼', '는', '다', '▁', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁오', '에', '▁', '겐', '자', '부', '로', '는', '▁일본', '▁현대', '문학', '의', '▁초', '석', '을', '▁놓', '은', '▁것으로', '▁평가', '받는', '▁작가', '▁나', '쓰', '메', '▁소', '세', '키', '▁(', '▁18', '67', '▁', '~', '▁19', '16', '▁', ')', '▁', '의', '▁대표', '작', '▁‘', '▁마음', '▁', '’', '▁', '에', '▁담긴', '▁군', '국', '주의', '적', '▁요소', '▁', ',', '▁야', '스', '쿠', '니', '▁신', '사', '▁참', '배', '▁행위', '까지', '▁소설', '의', '▁', '삽', '화', '로', '▁동원', '하며', '▁일본', '▁사회', '의', '▁‘', '▁비', '정', '상', '성', '▁', '’', '▁', '을', '▁문제', '▁삼', '는', '다', '▁', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = text.split()\n",
    "ret = []\n",
    "for text1 in texts:\n",
    "    ret.extend(tokenizer(text1))\n",
    "print(ret)\n",
    "ret == tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KoBERT vectorizer\n",
    "# :return:\n",
    "# ids, length, token_type_id\n",
    "tok_transform = nlp.data.BERTSentenceTransform(tokenizer, max_seq_length=30, pair=False)\n",
    "# KoBERT defines mask separately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2 3417 6896  517 5402 7147 6398 6079 5760 3809 5051 6237 7095 4501\n",
      " 6557 7088 1522 7086  909 4842 6290 3931 1370 6779 6190 2822 6579 7573\n",
      "  522    3]\n",
      "30\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_attention_mask(len_sent, valid_length):\n",
    "        attention_mask = np.zeros(len_sent)\n",
    "        attention_mask[:valid_length] = 1\n",
    "        return attention_mask\n",
    "input_ids, length, type_id = tok_transform((text,))\n",
    "attention_mask = get_attention_mask(len(input_ids), length)\n",
    "print(input_ids)\n",
    "print(length)\n",
    "print(type_id)\n",
    "print(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "## test\n",
    "#from gluonnlp.data import SentencepieceTokenizer, SentencepieceDetokenizer\n",
    "#tok2 = SentencepieceTokenizer(get_tokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁신', '지', '애', '-', '최', '경', '주', '▁부진', '한', '▁출발']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok2('신지애-최경주 부진한 출발')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오에 겐자부로는 일본 현대문학의 초석을 놓은 것으로 평가받는 작가 나쓰메 소세키(1867~1916)의 대표작 ‘마음’에 담긴 군국주의적 요소, 야스쿠니 신사 참배 행위까지 소설의 삽화로 동원하며 일본 사회의 ‘비정상성’을 문제 삼는다.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"첫 회를 시작으로 13일까지 4일간 총 4회에 걸쳐 매 회 2편씩 총 \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoBERT():\n",
    "    ## wrap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

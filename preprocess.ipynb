{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import pickle as pk\n",
    "from imp import reload\n",
    "\n",
    "from tagging import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport sys, importlib\\nimportlib.reload(sys.modules['tagging'])\\nfrom tagging import *\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import sys, importlib\n",
    "importlib.reload(sys.modules['tagging'])\n",
    "from tagging import *\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_train_s = '/home/bwlee/data/NER/exobrain'\n",
    "dir_val_s = '/home/bwlee/data/NER/exobrain_valid'\n",
    "\n",
    "files_train = [join(dir_train_s, f_s) for f_s in listdir(dir_train_s) \n",
    "             if isfile(join(dir_train_s, f_s))]\n",
    "files_val = [join(dir_val_s, f_s) for f_s in listdir(dir_val_s) \n",
    "             if isfile(join(dir_val_s, f_s))]\n",
    "files_test = ['test_exo_form2.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_a_file(f_s):\n",
    "    with open(f_s) as f1:\n",
    "        flag_text = False\n",
    "        text, tag_text = [], []\n",
    "        ii = 1\n",
    "        for line in f1:\n",
    "            if line[:2] != '##':\n",
    "                ii += 1\n",
    "                continue\n",
    "            \n",
    "            if re.match('## \\d+$', line):\n",
    "                flag_text = True\n",
    "                continue\n",
    "            else:\n",
    "                if flag_text:\n",
    "                    text.append(line[3:])\n",
    "                    flag_text = False\n",
    "                else:\n",
    "                    tag_text.append(line[3:])\n",
    "                    try:\n",
    "                        assert len(text) == len(tag_text)\n",
    "                    except:\n",
    "                        print(f_s, ii)\n",
    "                        raise Exception\n",
    "            ii += 1\n",
    "            \n",
    "    return text, tag_text\n",
    "\n",
    "sent_train = []\n",
    "tag_sent_train = []\n",
    "for f_s in files_train:\n",
    "    sent1, tag_sent1 = read_a_file(f_s)\n",
    "    sent_train.extend(sent1)\n",
    "    tag_sent_train.extend(tag_sent1)\n",
    "    \n",
    "sent_val = []\n",
    "tag_sent_val = []\n",
    "for f_s in files_val:\n",
    "    sent1, tag_sent1 = read_a_file(f_s)\n",
    "    sent_val.extend(sent1)\n",
    "    tag_sent_val.extend(tag_sent1)\n",
    "    \n",
    "sent_test = []\n",
    "tag_sent_test = []\n",
    "for f_s in files_test:\n",
    "    sent1, tag_sent1 = read_a_file(f_s)\n",
    "    sent_test.extend(sent1)\n",
    "    tag_sent_test.extend(tag_sent1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<삼성전자:ORG>가 디스플레이 관련 일회성 수익에 힘입어 시장 예상을 큰 폭 뛰어넘는 실적을 냈다.\\n',\n",
       " '<삼성전자:ORG>는 올해 <2분기:NOH> 연결 기준 영업이익이 전년 동기 대비 <22.73%:PNT> 증가한 <8조1천억원:MNY>으로 잠정 집계됐다고 <8일:DAT> 공시했다.\\n']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_sent_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자가 디스플레이 관련 일회성 수익에 힘입어 시장 예상을 큰 폭 뛰어넘는 실적을 냈다.\n",
      "\n",
      "<삼성전자:ORG>가 디스플레이 관련 일회성 수익에 힘입어 시장 예상을 큰 폭 뛰어넘는 실적을 냈다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ii in range(1):\n",
    "    print(sent_test[ii])\n",
    "    print(tag_sent_test[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "# SKT KoBERT\n",
    "import gluonnlp as nlp\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "# KoBERT tokenizer\n",
    "kobert, vocab = get_pytorch_kobert_model()\n",
    "tokenizer = nlp.data.BERTSPTokenizer(get_tokenizer(), vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "\n",
    "# BERT tokenizer\n",
    "B_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_exp = '<(.+?):([A-Z]{3})>'\n",
    "\n",
    "def get_token_tag(text, tag_text, tokenizer):\n",
    "    wp_tokens = token_loc(text, tokenizer)\n",
    "    ner_tokens = get_NE(tag_text, text, ne_exp)\n",
    "\n",
    "    # get matching ids\n",
    "    matching_ids = match(ner_tokens, wp_tokens)\n",
    "\n",
    "    # preprocess (TAG --> B-TAG or I-TAG)\n",
    "    tg_tags = [(i, x[1]) for i, x in enumerate(ner_tokens)]\n",
    "    tags = [None]*len(wp_tokens)\n",
    "    for ii, tag in tg_tags:\n",
    "        i_id, f_id = matching_ids[ii]\n",
    "        tags[i_id] = 'B-'+tag\n",
    "        for jj in range(i_id+1, f_id+1):\n",
    "            tags[jj] = 'I-'+tag\n",
    "    return [ x[0] for x in wp_tokens], [x if x is not None else 'O' for x in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, labels_train = [], []\n",
    "for sent1, tag_sent1 in zip(sent_train, tag_sent_train):\n",
    "    tokens, tags = get_token_tag(sent1, tag_sent1, tokenizer)\n",
    "    sentences_train.append(tokens)\n",
    "    labels_train.append(tags)\n",
    "    \n",
    "sentences_val, labels_val = [], []\n",
    "for sent1, tag_sent1 in zip(sent_val, tag_sent_val):\n",
    "    tokens, tags = get_token_tag(sent1, tag_sent1, tokenizer)\n",
    "    sentences_val.append(tokens)\n",
    "    labels_val.append(tags)\n",
    "    \n",
    "sentences_test, labels_test = [], []\n",
    "for sent1, tag_sent1 in zip(sent_test, tag_sent_test):\n",
    "    tokens, tags = get_token_tag(sent1, tag_sent1, tokenizer)\n",
    "    sentences_test.append(tokens)\n",
    "    labels_test.append(tags)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = sent_test[-1]\n",
    "tag_sent1 = tag_sent_test[-1]\n",
    "tokens, tags = get_token_tag(sent1, tag_sent1, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<카카오뱅크:ORG>는 오는 <13일:DAT>부터 다음 달 <2일:DAT>까지 '가져오기' 기능을 실행하고 이벤트에 참여한 고객에게 <아이패드:POH>, <애플워치:POH>, <편의점 상품권:POH> 등을 제공하는 이벤트도 진행한다.\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁카카오', '뱅', '크', '는', '▁오는', '▁13', '일부터', '▁다음', '▁달', '▁2', '일까지', \"▁'\", '▁가져', '오', '기', \"▁'\", '▁기능을', '▁실행', '하고', '▁이벤트', '에', '▁참여한', '▁고객에게', '▁아이', '패', '드', '▁', ',', '▁애플', '워', '치', '▁', ',', '▁편의점', '▁상품', '권', '▁등을', '▁제공하는', '▁이벤트', '도', '▁진행한다', '▁', '.']\n",
      "['B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'B-DAT', 'I-DAT', 'O', 'O', 'B-DAT', 'I-DAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-POH', 'I-POH', 'I-POH', 'O', 'O', 'B-POH', 'I-POH', 'I-POH', 'O', 'O', 'B-POH', 'I-POH', 'I-POH', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "<카카오뱅크:ORG>는 오는 <13일:DAT>부터 다음 달 <2일:DAT>까지 '가져오기' 기능을 실행하고 이벤트에 참여한 고객에게 <아이패드:POH>, <애플워치:POH>, <편의점 상품권:POH> 등을 제공하는 이벤트도 진행한다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ii = -1\n",
    "print(sentences_test[ii])\n",
    "print(labels_test[ii])\n",
    "print(tag_sent_test[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/kobert_data_train.pk', 'wb') as f1:\n",
    "    pk.dump((sentences_train, labels_train), f1)\n",
    "with open('data/kobert_data_val.pk', 'wb') as f1:\n",
    "    pk.dump((sentences_val, labels_val), f1)    \n",
    "with open('data/kobert_data_test.pk', 'wb') as f1:\n",
    "    pk.dump((sentences_test, labels_test), f1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_sentences_train, B_labels_train = [], []\n",
    "for sent1, tag_sent1 in zip(sent_train, tag_sent_train):\n",
    "    tokens, tags = get_token_tag(sent1, tag_sent1, B_tokenizer)\n",
    "    B_sentences_train.append(tokens)\n",
    "    B_labels_train.append(tags)\n",
    "    \n",
    "B_sentences_val, B_labels_val = [], []\n",
    "for sent1, tag_sent1 in zip(sent_val, tag_sent_val):\n",
    "    tokens, tags = get_token_tag(sent1, tag_sent1, B_tokenizer)\n",
    "    B_sentences_val.append(tokens)\n",
    "    B_labels_val.append(tags)\n",
    "    \n",
    "B_sentences_test, B_labels_test = [], []\n",
    "for sent1, tag_sent1 in zip(sent_test, tag_sent_test):\n",
    "    tokens, tags = get_token_tag(sent1, tag_sent1, B_tokenizer)\n",
    "    B_sentences_test.append(tokens)\n",
    "    B_labels_test.append(tags)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/bert_data_train.pk', 'wb') as f1:\n",
    "    pk.dump((B_sentences_train, B_labels_train), f1)\n",
    "with open('data/bert_data_val.pk', 'wb') as f1:\n",
    "    pk.dump((B_sentences_val, B_labels_val), f1)\n",
    "with open('data/bert_data_test.pk', 'wb') as f1:\n",
    "    pk.dump((B_sentences_test, B_labels_test), f1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁카카오', '뱅', '크', '는', '▁오는', '▁13', '일부터', '▁다음', '▁달', '▁2', '일까지', \"▁'\", '▁가져', '오', '기', \"▁'\", '▁기능을', '▁실행', '하고', '▁이벤트', '에', '▁참여한', '▁고객에게', '▁아이', '패', '드', '▁', ',', '▁애플', '워', '치', '▁', ',', '▁편의점', '▁상품', '권', '▁등을', '▁제공하는', '▁이벤트', '도', '▁진행한다', '▁', '.']\n",
      "['B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'B-DAT', 'I-DAT', 'O', 'O', 'B-DAT', 'I-DAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-POH', 'I-POH', 'I-POH', 'O', 'O', 'B-POH', 'I-POH', 'I-POH', 'O', 'O', 'B-POH', 'I-POH', 'I-POH', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences_test[-1])\n",
    "print(labels_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카카오뱅크는 오는 13일부터 다음 달 2일까지 '가져오기' 기능을 실행하고 이벤트에 참여한 고객에게 아이패드, 애플워치, 편의점 상품권 등을 제공하는 이벤트도 진행한다.\n",
      "\n",
      "<카카오뱅크:ORG>는 오는 <13일:DAT>부터 다음 달 <2일:DAT>까지 '가져오기' 기능을 실행하고 이벤트에 참여한 고객에게 <아이패드:POH>, <애플워치:POH>, <편의점 상품권:POH> 등을 제공하는 이벤트도 진행한다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sent_test[-1])\n",
    "print(tag_sent_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
